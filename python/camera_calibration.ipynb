{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera calibration notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The checkerboard in data/calibration_images is 7x10, so we define the size as\n",
    "checker_size = (6,9)\n",
    "# Define criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# 3D points for each checkerboard image\n",
    "objpoints = []\n",
    "# 2D points for each checkerboard image\n",
    "imgpoints = [] \n",
    "\n",
    "# World coordinates for 3D points..\n",
    "worldObjpoints = np.zeros((1, checker_size[0] * checker_size[1], 3), np.float32)\n",
    "# worldObjpoints = [[0,0,0], ..., [5,0,0], [0,1,0], ..., [5,1,0], [0,2,0], ..., [5,8,0]]\n",
    "worldObjpoints[0,:,:2] = np.mgrid[0:checker_size[0], 0:checker_size[1]].T.reshape(-1, 2)\n",
    "prev_img_shape = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the checkerboard size, i.e., expected number of corners, and the world coordinates of 3D points (as assumed above), we relate the `worldObjpoints` with the resulting pixel coordinates `corners` (below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting path of individual image stored in a given directory\n",
    "images = glob.glob('../data/calibration_images/*.jpg')\n",
    "for fname in images:\n",
    "    # Read image and convert to grayscale\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # We use the OpenCV function that finds corners of the checkerboard given 'checker_size'\n",
    "    found, corners = cv2.findChessboardCorners(gray, checker_size, cv2.CALIB_CB_ADAPTIVE_THRESH+cv2.CALIB_CB_FAST_CHECK+cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    \n",
    "    # If desired number of corner are found..\n",
    "    if (found):\n",
    "        objpoints.append(worldObjpoints)\n",
    "        # Refine the pixel coordinates using the cornerSubPix function\n",
    "        refined_corners = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(refined_corners)\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, checker_size, refined_corners, found)\n",
    "    \n",
    "    cv2.imshow('Calibration image', img)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `objpoints` and the corresponding `imgpoints`, we can find the mapping from one to the other using the `calibrateCamera` function, and the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The calibrateCamera function of OpenCV needs the value of known 3D points (objpoints)\n",
    "# and the corresponding detected pixel coordinates (imgpoints)\n",
    "ret, camMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "# Print values\n",
    "print(\"Camera matrix: \\n\")\n",
    "print(camMatrix)\n",
    "print(\"Distortion coefficients: \\n\")\n",
    "print(distCoeffs)\n",
    "print(\"rvecs: \\n\")\n",
    "print(rvecs)\n",
    "print(\"tvecs: \\n\")\n",
    "print(tvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can refine the derived camera parameters using `getOptimalNewCameraMatrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(images[0])\n",
    "h,w = img.shape[:2]\n",
    "# Refine the camera matrix using parameters obtained by calibration\n",
    "newCamMatrix, roi = cv2.getOptimalNewCameraMatrix(camMatrix, distCoeffs, (w,h), 1, (w,h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the camera parameters we can undistort an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 to undistort the image\n",
    "undst1 = cv2.undistort(img, camMatrix, distCoeffs, None, newCamMatrix)\n",
    "\n",
    "# Method 2 to undistort the image\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(camMatrix, distCoeffs, None, newCamMatrix, (w,h), 5)\n",
    "\n",
    "undst2 = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)\n",
    "\n",
    "# Displaying the undistorted image\n",
    "cv2.imshow(\"Undistorted image 1\", undst1)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Undistorted image 2\", undst2)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "728bfd8bfd3dbe0de9e5a7a3237efd086f7b49e9872433e4e2a8ea8790f34158"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
